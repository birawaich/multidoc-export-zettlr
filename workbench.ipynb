{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b79a15c-5470-4a35-93c0-9661f789d76d",
   "metadata": {},
   "source": [
    "# Workbench\n",
    "\n",
    "Notebook used to do development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0beeb-2520-4290-a0f3-53bde79b94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Build:\n",
    "    \"\"\"Class holding all the information how a build should look like and looks\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 title,\n",
    "                 author_name):\n",
    "        # Set Parameters\n",
    "        self.title = title\n",
    "        \"\"\"Title of the Build i.e. what is written at the top\"\"\"\n",
    "        self.author_name = author_name\n",
    "        \"\"\"Name of the Author\"\"\"\n",
    "\n",
    "        documents = []\n",
    "        \"\"\"documents to be included in build\"\"\"\n",
    "\n",
    "\n",
    "def create_build_from_yaml(filename_buildfile: str\n",
    "                           ) -> Build:\n",
    "    \"\"\"Creates a build file from a YAML document\n",
    "    \n",
    "    also initializes the single documents, but does not do any processing\"\"\"\n",
    "\n",
    "    # check if build file exists\n",
    "    \n",
    "    # extract YAML\n",
    "\n",
    "    # init build file\n",
    "\n",
    "    # set up documents\n",
    "\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f418ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YAML File\n",
    "filename_buildfile = \"build.yaml\"\n",
    "\n",
    "# extract documents from build file\n",
    "\n",
    "SingleDocument.verbose = True\n",
    "\n",
    "### Run\n",
    "\n",
    "documents = []\n",
    "SingleDocument.filepath_source = filepath_source\n",
    "SingleDocument.filepath_output = filepath_output\n",
    "for filename in filenames:\n",
    "    documents.append(SingleDocument(filename))\n",
    "    \n",
    "# for document in documents:\n",
    "#     print(document.get_markdown_text())\n",
    "#     print(document.get_latex_text())\n",
    "\n",
    "latex_total = merge_documents(documents=documents)\n",
    "latex_total = set_metadata_merged(latex_total,author=author,title=title)\n",
    "\n",
    "# print(latex_total)\n",
    "\n",
    "compile_latex(latex_total\n",
    "              ,output_directory=filepath_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b35f8d",
   "metadata": {},
   "source": [
    "# OLD WAY\n",
    "\n",
    "        ### STORING\n",
    "        self._markdown_mod = converted\n",
    "        return converted\n",
    "    \n",
    "    def _extend_yaml_header(self, content: str, new_key: str, new_value: str) -> str:\n",
    "        \"\"\"\n",
    "        Add a new metadata field to the YAML front matter in a given string. Adds a YAML formatter in case none exists.\n",
    "\n",
    "        Args:\n",
    "            yaml_string (str): The string containing the YAML front matter and document content.\n",
    "            new_key (str): The new metadata key to add.\n",
    "            new_value (str): The new metadata value to add.\n",
    "\n",
    "        Returns:\n",
    "            str: The updated string with the new metadata field added.\n",
    "        \"\"\"\n",
    "        # Define the regex pattern to match the YAML front matter block\n",
    "        pattern = r'^(\\-{3}\\s*\\n.*?\\n)(\\-{3}\\s*)'\n",
    "        replacement = f'\\\\1{new_key}: \\\"{new_value}\\\"\\n\\\\2'\n",
    "        \n",
    "        # Check if YAML front matter exists\n",
    "        if re.search(pattern, content, flags=re.DOTALL | re.MULTILINE):\n",
    "            # If YAML front matter exists, update it\n",
    "            updated_yaml_string = re.sub(pattern, replacement, content, flags=re.DOTALL | re.MULTILINE)\n",
    "        else:\n",
    "            # If YAML front matter does not exist, add it at the beginning\n",
    "            new_yaml_front_matter = f\"---\\n{new_key}: \\\"{new_value}\\\"\\n---\\n\"\n",
    "            updated_yaml_string = new_yaml_front_matter + content\n",
    "        \n",
    "        return updated_yaml_string\n",
    "    \n",
    "    def _extract_yaml_header(self, markdown_content: str):\n",
    "        # Use a regular expression to find the YAML header at the beginning of the file\n",
    "        yaml_header = re.match(r'^---\\n(.*?)\\n---', markdown_content, re.DOTALL)\n",
    "        if yaml_header:\n",
    "            yaml_content = yaml_header.group(1)\n",
    "            # Parse the YAML content\n",
    "            return yaml.safe_load(yaml_content)\n",
    "        return None\n",
    "    \n",
    "    # LATEX RELATED STUFF\n",
    "    \n",
    "    def _convert_to_latex(self) -> str:\n",
    "        \"\"\"Converts the modified markdown to latex, stores it, and returns it\"\"\"\n",
    "        if SingleDocument.verbose:\n",
    "            print(\"Converting modified markdown of file \"+self.filename+\" to Latex...\")\n",
    "\n",
    "        assert self._markdown_mod  is not None, \"need to have a modified markdown text first!\"\n",
    "\n",
    "        converted = pypandoc.convert_text(source=self._markdown_mod, to='latex',format='md'\n",
    "                                          ,filters=['pandocs_filters/curdir-reference-path-resources.lua'\n",
    "                                                    ,'pandocs_filters/set_graphics_width.lua'\n",
    "                                                    ,'pandocs_filters/mod-reference-path-resources.lua']\n",
    "                                        ,extra_args=[]) #wirte '--standalone' to see full latex output\n",
    "\n",
    "        self._latex_raw = converted\n",
    "\n",
    "        return converted\n",
    "    \n",
    "    def _modify_latex(self) -> str:\n",
    "        \"\"\"Modifies the raw latex string, stores it, and returns it\"\"\"\n",
    "        if SingleDocument.verbose:\n",
    "            print(\"Modifying raw latex of file \"+self.filename+\"...\")\n",
    "\n",
    "        assert self._latex_raw is not None, \"need to convert to latex first!\"\n",
    "\n",
    "        ### CONVERTIONS\n",
    "\n",
    "        # use metadata if available\n",
    "        header = ''\n",
    "\n",
    "        if self._metadata:\n",
    "            metadata: dict = self._metadata\n",
    "            if \"title\" in metadata:\n",
    "                header += \"\\\\mezdoctitle{\"+metadata[\"title\"]+\"}\\n\\n\"\n",
    "\n",
    "        converted = header + self._latex_raw\n",
    "\n",
    "        # scale images to \\columnwidth in case there is no width yet\n",
    "        converted = self._add_width_to_includegraphics(converted)\n",
    "\n",
    "        # make floats floating due to issues in multicolumn\n",
    "        # (https://tex.stackexchange.com/questions/12262/multicol-and-figures)\n",
    "        converted = self._add_option_H_to_figures(converted)\n",
    "\n",
    "        # convert all internal refererences to the latex command\n",
    "        converted = self._replace_zettler_internal_link_with_command(converted)\n",
    "\n",
    "        ### STORING\n",
    "        self._latex_mod = converted\n",
    "        return converted\n",
    "    \n",
    "    def _add_width_to_includegraphics(self, content: str) -> str:\n",
    "        \"\"\"looks for all includegraphics and adds `\\columnwidth` to the graphics in case there \n",
    "        is no defined with or height yet\"\"\"\n",
    "\n",
    "        CM_IN_INCH = 2.54 #conversion from CM to INCH\n",
    "        DPI_PICTURES = 300 #\"true\" DPI the pictures have\n",
    "        DPI_INTERNAL = 96 #amount of DPI that pandocs uses to convert px --> inch\n",
    "        MAX_SIZE_IMAGE_CM = 8.0 #maximal width of an image in CM\n",
    "\n",
    "\n",
    "        # Regex pattern to find \\includegraphics commands\n",
    "        pattern = re.compile(r'(\\\\includegraphics)(\\[[^\\]]*\\])?(\\{[^}]*\\})')\n",
    "\n",
    "        def extract_numbers_from_match(match):\n",
    "            #extract the inches values from a match that looks like '[width=2.66667in,height=2.66667in]'\n",
    "            pattern = r'(\\d+\\.?\\d*)'\n",
    "            # Use re.findall() to extract all matching numbers\n",
    "            numbers = re.findall(pattern, match)\n",
    "            # Convert the extracted strings to floats\n",
    "            numbers = [float(num) for num in numbers]\n",
    "            return numbers\n",
    "\n",
    "        def replace_match(match):\n",
    "            prefix, options, filename = match.groups()\n",
    "            if options is None:\n",
    "                # No options provided, add width=\\columnwidth\n",
    "                return f'{prefix}[width=0.8\\\\columnwidth]{filename}'\n",
    "            elif 'width=' not in options and 'height=' not in options:\n",
    "                # Options provided but without width or height, add width=\\columnwidth\n",
    "                return f'{prefix}[width=0.8\\\\columnwidth{options[1:]}{filename}'\n",
    "            else:\n",
    "                # Options already contain width or height: scale it down and if too\n",
    "                # large do scale\n",
    "                width, height = extract_numbers_from_match(options)\n",
    "                # convert to cm and scale down according to DPI\n",
    "                width *= CM_IN_INCH * DPI_INTERNAL / DPI_PICTURES\n",
    "                height *= CM_IN_INCH * DPI_INTERNAL / DPI_PICTURES\n",
    "\n",
    "                # check if width is too wide --> then return the columnwidth\n",
    "                if(width > MAX_SIZE_IMAGE_CM):\n",
    "                    return f'{prefix}[width=0.8\\\\columnwidth]{filename}'\n",
    "                \n",
    "                return f'{prefix}[width={width}cm,height={height}cm]{filename}'\n",
    "\n",
    "        # Replace all matches in the content\n",
    "        new_content = pattern.sub(replace_match, content)\n",
    "        \n",
    "        return new_content\n",
    "     \n",
    "    def _add_option_H_to_figures(self, latex_text: str) -> str:\n",
    "        # Regular expression to find figure environments without any options\\n\",\n",
    "        pattern = r'(\\\\begin{figure})(?!\\[\\w*\\])'\n",
    "        # Replace those occurrences with the same string but with [H] appended\n",
    "        replacement = r'\\1[H]'\n",
    "\n",
    "        modified_text = re.sub(pattern, replacement, latex_text)\n",
    "        \n",
    "        return modified_text\n",
    "   \n",
    "    def _replace_zettler_internal_link_with_command(self, latex_text: str) -> str:\n",
    "        # replaces `[[20240719012226]]` with the latex command for it\n",
    "\n",
    "        pattern = re.compile(r'\\{\\[\\}\\{\\[\\}\\d{14}\\{\\]\\}\\{\\]\\}') #note: the [[ ]] are compiled into {[}... for soem reason\n",
    "        # Replace the pattern with \\somecommand\n",
    "        result = pattern.sub(r'\\\\mezintreference', latex_text)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def merge_documents(documents: list[SingleDocument]) -> str:\n",
    "    \"\"\"Merges a bunch of documents into a single latex stirng\"\"\"\n",
    "\n",
    "    concat = ''\n",
    "\n",
    "    for document in documents:\n",
    "        latex = document.get_latex_text()\n",
    "\n",
    "        # wrap it into a minipage\n",
    "        # latex = \"\\\\begin{minipage}{\\columnwidth}\\n\"\\\n",
    "        #     + latex +\"\\n\"\\\n",
    "        #     + \"\\end{minipage}\\n\"\n",
    "        \n",
    "        # concatenate it\n",
    "        concat += latex\n",
    "\n",
    "    # put it into the tempalte\n",
    "    with open('template/template_outputfile.tex','r') as templatefile:\n",
    "        template_latex = templatefile.read()\n",
    "\n",
    "    merged = template_latex.replace('%%<content_placeholder>%%',concat)\n",
    "\n",
    "    return merged\n",
    "\n",
    "def set_metadata_merged(text: str, author:str, title: str) -> str:\n",
    "    \"\"\"set the author and the title metadat in the results\"\"\"\n",
    "\n",
    "    text = text.replace('%%<TITLE>%%',title)\n",
    "    text = text.replace('%%<AUTHOR>%%',author)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed01fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.singledocument import SingleDocument\n",
    "from src.functions import *\n",
    "\n",
    "### Settings\n",
    "\n",
    "author = \"Ford Prefect\"\n",
    "\n",
    "filenames = ['sample1.md','sample2.md','sample3.md', 'sample4.md']\n",
    "filenames = ['sample3.md']\n",
    "filepath_source = 'sample/'\n",
    "filepath_output = 'out/'\n",
    "title = \"Test Samples\"\n",
    "\n",
    "\n",
    "SingleDocument.verbose = True\n",
    "\n",
    "### Run\n",
    "\n",
    "documents = []\n",
    "SingleDocument.filepath_source = filepath_source\n",
    "SingleDocument.filepath_output = filepath_output\n",
    "for filename in filenames:\n",
    "    documents.append(SingleDocument(filename))\n",
    "    \n",
    "for document in documents:\n",
    "    print(document.get_markdown_text())\n",
    "    print(document.get_latex_text())\n",
    "\n",
    "latex_total = merge_documents(documents=documents)\n",
    "latex_total = set_metadata_merged(latex_total,author=author,title=title)\n",
    "\n",
    "# print(latex_total)\n",
    "\n",
    "compile_latex(latex_total\n",
    "              ,output_directory=filepath_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076a94aa",
   "metadata": {},
   "source": [
    "Non-Sample Exports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc71640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = ['general_control_diagram.md' #Basics\n",
    "#              ,'optimization-based-control.md'\n",
    "#              ,'linear_time-invariant_system.md'\n",
    "#              ,'bellmans-principle-optimality.md' \n",
    "#              ,'markovian_representation.md'\n",
    "#              ,'SISO_system.md'\n",
    "#              ,'MIMO_system.md'\n",
    "#              ,'dpa_dynamic-programming-approch.md'\n",
    "#              ,'optimal-linear-quadratic-regulation.md' #LQR\n",
    "#              ,'lqr_finite-horizon.md'\n",
    "#              ,'lqr_infinite-horizon.md'\n",
    "#              ,'affine-lqr.md'\n",
    "#              ,'model-predictive-control.md' # MPC\n",
    "#              ,'mpc_stability.md'\n",
    "#              ,'lyapunov_analysis.md'\n",
    "#              ,'mpc_incremental-mpc.md'\n",
    "#              ,'mpc_explicit.md'\n",
    "#              ,'mpc_steady-state-selection.md'\n",
    "#              ,'disturbances.md'\n",
    "#              ,'mpc_disturbance-rejection.md'\n",
    "#              ,'robust_mpc.md'\n",
    "#              ,'robust-mpc_feedback-mpc.md'\n",
    "#              ,'mpc_robust-mpc_soft-constrained-lqr.md'\n",
    "#              ,'economic-mpc.md'\n",
    "#              ,'behavioral-system-theory.md' #Identification\n",
    "#              ,'system-identification.md'\n",
    "#              ,'markov-parameters.md'\n",
    "#              ,'controllability.md'\n",
    "#              ,'controllability-matrix.md'\n",
    "#              ,'observability.md'\n",
    "#              ,'observability-matrix.md'\n",
    "#              ,'impulse_response.md'\n",
    "#              ,'kalman-ho_algorithm.md'\n",
    "#              ,'data-enabled-predictive-control.md' #DeepC\n",
    "#              ,'behavioral_K-step-predictor.md'\n",
    "#              ,'hankel-matrix.md'\n",
    "#              ,'deepc_regularized.md'\n",
    "#              ,'markov-decision-process.md' #MDP\n",
    "#              ,'markov-chain.md'\n",
    "#              ,'policy_for-mdp.md'\n",
    "#              ,'mdp_control-problem.md'\n",
    "#              ,'mdp_q-function.md'\n",
    "#              ,'mdp_value-function.md'\n",
    "#              ,'mdp_finite-horizon.md'\n",
    "#              ,'mdp_infinite-horizon.md'\n",
    "#              ,'monte-carlo-learning.md' #Monte Carlo\n",
    "#              ,'reinforcement-learning.md' #RL\n",
    "#              ,'sarsa_temporal-difference.md'\n",
    "#              ,'q-learning.md'\n",
    "#              ,'policy-gradient.md'\n",
    "#              ]\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/CS2__computational-control/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"Computational Control\"\n",
    "\n",
    "# filenames = ['antrieb_eisenbahn.md'\n",
    "#              ,'antrieb-elektrisch.md'\n",
    "#              ,'haupttransformator.md'\n",
    "#              ,'drosselspule_dc.md'\n",
    "#              ,'fahrmotoren.md'\n",
    "#              ,'elektromotor.md'             \n",
    "#              ,'asynchron-motor.md'\n",
    "#              ,'stromrichter.md'\n",
    "#              ,'netzstromrichter.md'\n",
    "#              ,'zwischenkreis.md'\n",
    "#              ,'motorstromrichter.md'\n",
    "#              ,'hochspannung_eisenbahn.md'\n",
    "#              ,'thermische_auslegung.md'\n",
    "#              ,'diesel-antrieb.md'\n",
    "#              ,'diesel-machanisch.md'\n",
    "#              ,'diesel-hydrostatisch.md'\n",
    "#              ,'diesel-hydrodynamisch.md'\n",
    "#              ,'diesel-elektrisch_gleichstrom.md'\n",
    "#              ,'diesel-elektrisch_umrichter.md'\n",
    "#              ,'gasturbinen-antrieb.md'\n",
    "#              ,'sicherheitssteuerung.md'\n",
    "#              ,'zugbeeinflussung.md'\n",
    "#              ,'etcs.md'\n",
    "#              ,'2024-03-22_sbb-etcs.md'\n",
    "#              ,'energieverbrauch.md'\n",
    "#              ,'energiespeicher.md'\n",
    "#              ,'2024-04-12_traktionsbaterien-gastvortrag.md'\n",
    "#              ,'bahnstromversorgung.md'\n",
    "#              ,'gleichstromsysteme.md'\n",
    "#              ,'wechselstromsystem_sonderfrequenz.md'\n",
    "#              ,'wechselstromsysteme_industriefrequenz.md'\n",
    "#              ,'elektrische-systemkompatibilitaet.md'\n",
    "#              ,'gleisstromkreis.md'\n",
    "#              ,'achsenzaehler.md'\n",
    "#              ,'netzimpendanz.md']\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/EST2__eisenbahn-systemtechnik-2/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"Eisenbahn-Systemtechnik 2\"\n",
    "\n",
    "# filenames = ['BDE_l01.md'\n",
    "#              ,'BDE_l02.md'\n",
    "#              ,'BDE_l03.md'\n",
    "#              ,'BDE_l04.md'\n",
    "#              ,'BDE_l05.md'\n",
    "#              ,'BDE_l06.md'\n",
    "#              ,'BDE_l07.md'\n",
    "#              ,'BDE_l08.md'\n",
    "#              ,'BDE_l09.md'\n",
    "#              ,'BDE_l10.md'\n",
    "#              ,'BDE_l11.md'\n",
    "#              ,'BDE_l12.md'\n",
    "#              ,'BDE_l13.md'\n",
    "#              ,'BDE_l14.md']\n",
    "# filenames = ['big-data_stack.md' #STACK\n",
    "#              ,'big_data.md' #GENERAL\n",
    "#              ,'relational-database.md'\n",
    "#              ,'sql.md'\n",
    "#              ,'data-types.md'\n",
    "#              ,'cloud-storage.md' #Storage\n",
    "#              ,'object-stores.md'\n",
    "#              ,'amazon_s3.md'\n",
    "#              ,'azure-blob-storage.md'\n",
    "#              ,'key-value-storage.md'\n",
    "#              ,'distributed-file-system.md' #DFS\n",
    "#              ,'hdfs.md'\n",
    "#              ,'googlefs.md'\n",
    "#              ,'csv.md' #SYNTAX\n",
    "#              ,'syntax_tree.md'\n",
    "#              ,'json.md'\n",
    "#              ,'xml.md'\n",
    "#              ,'data-formats.md'\n",
    "#              ,'data-model.md' #Data Models\n",
    "#              ,'json-data-model.md'\n",
    "#              ,'xml-information-set.md'\n",
    "#              ,'validation.md' #Validation\n",
    "#              ,'jsound.md'\n",
    "#              ,'json_schema.md'\n",
    "#              ,'xml-schema.md'\n",
    "#              ,'dataframe.md'\n",
    "#              ,'map-reduce.md' #Processing\n",
    "#              ,'yarn.md'\n",
    "#              ,'apache-spark.md'\n",
    "#              ,'wide-column-store.md' #DATA STORE, Wide Column Store\n",
    "#              ,'hbase.md'\n",
    "#              ,'spanner.md'\n",
    "#              ,'document-stores.md' #Document Store\n",
    "#              ,'mongo-db.md'\n",
    "#              ,'querying-trees.md' #Querying\n",
    "#              ,'jsoniq.md'\n",
    "#              ]\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/BDE__big-data-for-engineers/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"Big Data for Engineers\"\n",
    "\n",
    "# filenames = ['ch01.md'\n",
    "#              ,'ch02.md'\n",
    "#              ,'ch03.md'\n",
    "#              ,'ch04.md'\n",
    "#              ,'ch05.md'\n",
    "#              ,'ch06.md'\n",
    "#              ,'ch07.md'\n",
    "#              ,'ch08.md'\n",
    "#              ,'ch09.md'\n",
    "#              ,'ch10.md'\n",
    "#              ,'ch10b.md'\n",
    "#              ,'ch11.md'\n",
    "#              ,'ch12.md'\n",
    "#              ,'ch13.md'\n",
    "#              ,'ch14.md'\n",
    "#              ,'chapter_summaries.md'\n",
    "#              ,'practice-case_01.md'\n",
    "#              ,'practice-case-02.md'\n",
    "#              ,'practice-case-03.md'\n",
    "#              ,'practice-case-04.md'\n",
    "#              ,'practice-case-05.md'\n",
    "#              ,'practice-case-06.md'\n",
    "#              ,'guest-forrs.md'\n",
    "#              ,'guest_lea-bloechlinger.md'\n",
    "#              ,'guest_gas.md'\n",
    "#              ,'options.md'\n",
    "#              ,'merit-order.md'\n",
    "#              ,'marginal-cost.md'\n",
    "#              ,'ch_energiezukunft2050.md'\n",
    "#              ]\n",
    "# # filenames = ['chapter_summaries.md']\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/PM2__power-markets-2/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"Power Markets 2\"\n",
    "\n",
    "# filenames = ['L01.md'\n",
    "#              ,'l02.md'\n",
    "#              ,'discrete-event-system.md'\n",
    "#              ,'continous-variable-dynamic-system.md'\n",
    "#              ,'hybrid-system.md'\n",
    "#              ]\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/PEO__performance-evaluation-and-optimization-of-complex-systems/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"PEO (notes so far)\"\n",
    "\n",
    "# filenames = ['supply-chain.md'\n",
    "#              ,'inventory-management.md'             \n",
    "#              ,'economic-order-quantity.md'\n",
    "#              ,'safety-inventory.md'\n",
    "#              ,'ordering-policies.md'\n",
    "#              ,'inventory-management_quantity-discounts.md'\n",
    "#              ,'2024-09-09_logistics-supply-chain-management.md'\n",
    "#              ,'L02.md'\n",
    "#              ]\n",
    "# filenames = ['supply-chain.md',\n",
    "#              'network-design.md',\n",
    "#              'demand-forecasting.md',\n",
    "#              'logistics.md',\n",
    "#              'vehicle-routing-problem.md',\n",
    "#              'travelling-salesperson.md',\n",
    "#              'smart-warehouse.md'\n",
    "#              ]\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/LSCM__logistics-and-supply-chain-management/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"LSCM\"\n",
    "\n",
    "# filenames = ['statistics.md', #intro\n",
    "#              'statistical-inference.md',\n",
    "#              'bayesian-decison-theory.md', #Bayesian Decision Theory\n",
    "#              'generalized-bayesian-decision-theory.md',\n",
    "#              'bayes-inference.md', #Bayesian Framework\n",
    "#              'bayes-formula.md',\n",
    "#              'hypothesis-testing.md', #hpothesis testing\n",
    "#              'bayesian-hyptohesis-testing.md',\n",
    "#              'neyman-pearson_binary.md',\n",
    "#              'minimax-hypothesis-testing.md',\n",
    "#              'minimax-inequality.md',\n",
    "#              'operating-characteristic.md',\n",
    "#              'efficient-frontier.md',\n",
    "#              'hypothesis-testing_performance-limits.md',\n",
    "#              'randomized-hypothesis-test.md',\n",
    "#              'estimation.md',#estimation\n",
    "#              'bayesian-parameter-estimation.md',\n",
    "#              'linear-least-squares_estimation.md',\n",
    "#              'non-bayesian_parameter_estimation.md', #non bayes estimation\n",
    "#              'mvu_estimator.md',\n",
    "#              'cramer-rao-bound.md',\n",
    "#              'fisher-information.md',\n",
    "#              'efficient_estimator.md',\n",
    "#              'maximum-liklihood-estimation.md',\n",
    "#              'exponential-families.md',#exponential families\n",
    "#              'sufficient-statistics.md', #sufficient statistics\n",
    "#              'conjugate-priors.md', #conjugate priors\n",
    "#              'entropy.md', #information theory\n",
    "#              'mutual-information.md',\n",
    "#              'information-divergence.md',\n",
    "#              'data-process-inequality.md',\n",
    "#              'information-geometry.md', #information geometry\n",
    "#              'probability-simplex.md',\n",
    "#              'information-projection.md',\n",
    "#              'pythagoras_information.md',\n",
    "#              'pythagoras-identity.md',\n",
    "#              'linear-families.md',\n",
    "#              'EM-ML_algorithm.md', #EM Algorithm\n",
    "#              'reverse-i-projection.md',\n",
    "#              'em-ml_algorithm_as-projection.md',\n",
    "#              'weak-law-large-numbers.md', #Asymptotic Analysis\n",
    "#              'typical-sequence.md',\n",
    "#              'divergence-typical-set.md',\n",
    "#              'cramers-theorem.md',\n",
    "#              'gaussian-random-variable.md',#basics\n",
    "#              'gaussian-mixture-model.md',\n",
    "#              'gibbs-inequality.md',\n",
    "#              'graphical-models.md', #GRAPHICAL MODELS\n",
    "#              'clique.md',\n",
    "#              ]\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/STI__statistical-inference/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"STI\"\n",
    "\n",
    "# filenames = [\n",
    "#     '_CNS.md',\n",
    "#     '2024-09-09_china-studies_l01.md',\n",
    "#     'L02.md',\n",
    "#     'L03.md',\n",
    "#     'L04.md',\n",
    "#     'L05.md',\n",
    "#     'L06.md',\n",
    "#     'L07.md',\n",
    "#     'l08.md',\n",
    "#     'L10.md',\n",
    "#     'L11.md',\n",
    "#     'L12.md',\n",
    "#     'L13.md',\n",
    "#     'L14.md',             \n",
    "#              ]\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/CNS__china-studies_industry-economy-society/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"China Studies: Industry, Society and Culture\"\n",
    "\n",
    "filenames = [\n",
    "    'L01.md',\n",
    "    'l02.md',\n",
    "    'L03.md',\n",
    "    'l04.md',\n",
    "    'L05.md',\n",
    "    'L06.md',\n",
    "    'L07.md',\n",
    "    'L08.md',\n",
    "    'L09.md',\n",
    "    'L10.md',\n",
    "    'L11.md',\n",
    "    'L12.md',\n",
    "    'L13.md',\n",
    "    'L14.md',\n",
    "    'L15.md',\n",
    "             ]\n",
    "filepath_source = '../../polybox/ZETTLR_STUDIES/PEO__performance-evaluation-and-optimization-of-complex-systems/'\n",
    "filepath_output = 'out/'\n",
    "title = \"[PEO] Lecture Notes\"\n",
    "\n",
    "filenames = [\n",
    "    'bellmans-principle-optimality.md',\n",
    "    'markov-decision-process.md',\n",
    "    'mdp_control-problem.md',\n",
    "    'policy_for-mdp.md',\n",
    "    'mdp_q-function.md',\n",
    "    'mdp_value-function.md',\n",
    "    'reinforcement-learning.md',\n",
    "             ]\n",
    "filepath_source = '../../polybox/ZETTLR_STUDIES/CS2__computational-control/'\n",
    "filepath_output = 'out/'\n",
    "title = \"[PEO] CS2 Helpers\"\n",
    "\n",
    "# filenames = [\n",
    "#     'discrete-event-system.md', #DEDS et al\n",
    "#     'using_deds.md',\n",
    "#     'continous-variable-dynamic-system.md',\n",
    "#     'hybrid-system.md',    \n",
    "#     'ordinal-optimization.md', #ordinal optimization\n",
    "#     'vector_ordinal-optimization.md',\n",
    "#     'constrained-ordinal-optimization.md',\n",
    "#     'witsenhausen-problem.md', #(could also go somewhere else)\n",
    "#     'bellman-equation.md', #MDP stuff\n",
    "#     'value-iteration.md',\n",
    "#     'policy-iteration.md',\n",
    "#     'mdp_practice.md',\n",
    "#     'markov-reward-process.md', #RL Stuff\n",
    "#     'temporal-difference-lambda-methods.md',\n",
    "#     'policy-gradient-based-rl.md',\n",
    "#     'actor-critic-rl.md',\n",
    "#     'ebo_event.md', #Event and EBO\n",
    "#     'event-based-optimization.md',\n",
    "#     'no-free-lunch-theorem.md', #NFLT\n",
    "#     'ocba.md', #OCBA\n",
    "#     'mathematical-system.md', #BASICS\n",
    "#     'state.md',\n",
    "#     'system-theory.md',\n",
    "#     'control.md',\n",
    "#              ]\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/PEO__performance-evaluation-and-optimization-of-complex-systems/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"Performance Evaluation and Optimization of Complex Systems\"\n",
    "\n",
    "# filenames = ['hypothesis-testing.md'\n",
    "#              ,'bayesian-hyptohesis-testing.md'\n",
    "#              ,'neyman-pearson_binary.md'\n",
    "#              ,'minimax-hypothesis-testing.md'\n",
    "#              ,'operating-characteristic.md'\n",
    "#              ,'estimators.md'\n",
    "#              ,'bayesian-parameter-estimation.md'\n",
    "#              ,'linear-least-squares_estimation.md'\n",
    "#              ,'bayes-formula.md'\n",
    "#              ]\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/STI__statistical-inference/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"STI (notes so far)\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
