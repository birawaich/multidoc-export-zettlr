{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b79a15c-5470-4a35-93c0-9661f789d76d",
   "metadata": {},
   "source": [
    "# Workbench\n",
    "\n",
    "Notebook used to do development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0beeb-2520-4290-a0f3-53bde79b94fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "import os\n",
    "import subprocess\n",
    "import yaml\n",
    "import re\n",
    "\n",
    "def compile_latex(latex_content: str\n",
    "                               , output_directory: str='out'\n",
    "                               , tex_filename: str='document.tex'\n",
    "                               , pdf_filename: str='document.pdf') -> str:\n",
    "    \"\"\"\n",
    "    Compile a LaTeX file to a PDF using some engine (so far: pdflatex).\n",
    "\n",
    "    Args:\n",
    "        tex_filepath (str): The path to the LaTeX (.tex) file to be compiled.\n",
    "        output_directory (str): The directory where the compiled PDF should be saved. Default is 'output'.\n",
    "        pdf_filename (str): The name of the generated PDF file. Default is 'document.pdf'.\n",
    "\n",
    "    Returns:\n",
    "        str: The path to the generated PDF file if compilation is successful, None otherwise.\n",
    "\n",
    "    Note: Written with ChatGPT\n",
    "    \"\"\"\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    \n",
    "    # Write the LaTeX content to a .tex file\n",
    "    tex_filepath = os.path.join(output_directory, tex_filename)\n",
    "    with open(tex_filepath, 'w') as tex_file:\n",
    "        tex_file.write(latex_content)\n",
    "    \n",
    "    # Compile the .tex file to a PDF using pdflatex\n",
    "    try:\n",
    "        process = subprocess.run(['pdflatex', '-halt-on-error'\n",
    "                                  , '-output-directory', output_directory, tex_filepath],\n",
    "                                 stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        \n",
    "        # Check for errors\n",
    "        if process.returncode != 0:\n",
    "            print(\"Error during LaTeX compilation:\")\n",
    "            print(process.stdout)\n",
    "            print(process.stderr)\n",
    "            return None\n",
    "        else:\n",
    "            print(\"Compilation successful\")\n",
    "        \n",
    "        # Return the path to the generated PDF\n",
    "        return os.path.join(output_directory, pdf_filename)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "class SingleDocument:\n",
    "    \"\"\"Class holding information for a single document\"\"\"\n",
    "\n",
    "    ### CLASS VARIABLES\n",
    "    filepath_source: str = ''\n",
    "    \"\"\"Path to which the filename is relative\"\"\"\n",
    "\n",
    "    filepath_output: str = ''\n",
    "    \"\"\"Filepath relative to CWD where output files will lie\n",
    "    \n",
    "    Used to correctly link resources for Latex generation\"\"\"\n",
    "\n",
    "    verbose: bool = True\n",
    "    \"\"\"Set to True for verbose info\"\"\"\n",
    "\n",
    "    def __init__(self,filename: str):\n",
    "        # set instance variables\n",
    "        self.filename = filename\n",
    "        self._markdown_raw: str = None #markdown file content as text (raw = unmodified)\n",
    "        self._markdown_mod: str = None #markdown file content as text (modified)\n",
    "        self._latex_raw: str = None #latex representation of file (raw = unmodified)\n",
    "        self._latex_mod: str = None #latex representation of file (modified)\n",
    "\n",
    "        self._metadata: dict = None #dictionary holding metadata\n",
    "        return\n",
    "    \n",
    "    ### PUBLIC\n",
    "    \n",
    "    def get_markdown_text(self) -> str:\n",
    "        \"\"\"return the (modified) markdown text of this document\n",
    "        \n",
    "        if it has not been loaded, it will do so\"\"\"\n",
    "\n",
    "        if self._markdown_mod is not None:\n",
    "            return self._markdown_mod\n",
    "        \n",
    "        if self._markdown_raw is not None:\n",
    "            return self._modify_markdown()\n",
    "        \n",
    "        self._read_markdown_text()\n",
    "        return self._modify_markdown()\n",
    "    \n",
    "    def get_latex_text(self) -> str:\n",
    "        \"\"\"return the latex text of this document\n",
    "        \n",
    "        loads and converts it if needed\"\"\"\n",
    "\n",
    "        if self._latex_mod is not None:\n",
    "            return self._latex_mod\n",
    "        \n",
    "        if self._latex_raw is not None:\n",
    "            return self._modify_latex()\n",
    "        \n",
    "        self.get_markdown_text() #get and modify markdown\n",
    "        self._convert_to_latex()\n",
    "        return self._modify_latex()\n",
    "\n",
    "    \n",
    "    ### PRIVATE\n",
    "\n",
    "    def _read_markdown_text(self) -> str:\n",
    "        \"\"\"Reads the file specified by the filename, stores it, and returns it\n",
    "        \n",
    "        also loads the metadata\"\"\"\n",
    "        if SingleDocument.verbose:\n",
    "            print(\"Reading content of file \"+self.filename+\"...\")\n",
    "\n",
    "        filepath = SingleDocument.filepath_source + self.filename\n",
    "        assert os.path.exists(filepath), \\\n",
    "            \"Document \"+filepath+\" does not exist!\"\n",
    "        \n",
    "        with open(filepath,'r',encoding='utf-8') as file:\n",
    "            assert file.readable(), \"File \"+filepath+\" is not readable!\"\n",
    "            content = file.read()\n",
    "\n",
    "        ### Extract Metadata\n",
    "        self._metadata = self._extract_yaml_header(content)\n",
    "\n",
    "        self._markdown_raw = content\n",
    "        return content\n",
    "    \n",
    "    def _modify_markdown(self) -> str:\n",
    "        \"\"\"Modifies the raw markdown string, stores it, and returns it\"\"\"\n",
    "        if SingleDocument.verbose:\n",
    "            print(\"Mopdifying raw markdown of file \"+self.filename+\"...\")\n",
    "\n",
    "        assert self._markdown_raw is not None, \"need to load raw markdown first!\"\n",
    "\n",
    "        ### CONVERTIONS\n",
    "        converted = self._markdown_raw\n",
    "\n",
    "        # add relative path to metadata\n",
    "        relative_path = os.path.relpath(self.filepath_source, start=self.filepath_output)\n",
    "        converted = self._extend_yaml_header(content=converted, new_key=\"resource_path_mod\"\n",
    "                                             ,new_value=relative_path)\n",
    "        # add relative path from current directory\n",
    "        relative_path_curdir = os.path.relpath(self.filepath_source)\n",
    "        converted = self._extend_yaml_header(content=converted, new_key=\"resource_path_mod_curdir\"\n",
    "                                             ,new_value=relative_path_curdir)\n",
    "        \n",
    "        # take care of non-supported latex characters\n",
    "        converted = converted.replace('\\u219D', '$\\leadsto$') #↝\n",
    "        converted = converted.replace('\\u21D2', '$\\Rightarrow$') #⇒ (U+21D2)\n",
    "        converted = converted.replace('\\u21D0', '$\\Leftarrow$') #⇐ (U+21D0)\n",
    "        converted = converted.replace('\\u2194', '$\\leftrightarrow$') #↔ (U+2194)\n",
    "        converted = converted.replace('\\u21D4', '$\\Leftrightarrow$')#⇔ (U+21D4)\n",
    "        converted = converted.replace('\\u2264', '$\\leq$')#≤ (U+2264)\n",
    "        converted = converted.replace('\\u2265', '$\\geq$')#≥ (U+2265)\n",
    "        converted = converted.replace('\\u2260', '$\\\\neq$')#≠ (U+2260)\n",
    "        converted = converted.replace('\\u2154', '$\\\\frac{2}{3}$')#⅔ (U+2154)\n",
    "        converted = converted.replace('\\u2153', '$\\\\frac{1}{3}$')#⅓ (U+2153)\n",
    "\n",
    "        ### STORING\n",
    "        self._markdown_mod = converted\n",
    "        return converted\n",
    "    \n",
    "    def _extend_yaml_header(self, content: str, new_key: str, new_value: str) -> str:\n",
    "        \"\"\"\n",
    "        Add a new metadata field to the YAML front matter in a given string. Adds a YAML formatter in case none exists.\n",
    "\n",
    "        Args:\n",
    "            yaml_string (str): The string containing the YAML front matter and document content.\n",
    "            new_key (str): The new metadata key to add.\n",
    "            new_value (str): The new metadata value to add.\n",
    "\n",
    "        Returns:\n",
    "            str: The updated string with the new metadata field added.\n",
    "        \"\"\"\n",
    "        # Define the regex pattern to match the YAML front matter block\n",
    "        pattern = r'^(\\-{3}\\s*\\n.*?\\n)(\\-{3}\\s*)'\n",
    "        replacement = f'\\\\1{new_key}: \\\"{new_value}\\\"\\n\\\\2'\n",
    "        \n",
    "        # Check if YAML front matter exists\n",
    "        if re.search(pattern, content, flags=re.DOTALL | re.MULTILINE):\n",
    "            # If YAML front matter exists, update it\n",
    "            updated_yaml_string = re.sub(pattern, replacement, content, flags=re.DOTALL | re.MULTILINE)\n",
    "        else:\n",
    "            # If YAML front matter does not exist, add it at the beginning\n",
    "            new_yaml_front_matter = f\"---\\n{new_key}: \\\"{new_value}\\\"\\n---\\n\"\n",
    "            updated_yaml_string = new_yaml_front_matter + content\n",
    "        \n",
    "        return updated_yaml_string\n",
    "    \n",
    "    def _extract_yaml_header(self, markdown_content: str):\n",
    "        # Use a regular expression to find the YAML header at the beginning of the file\n",
    "        yaml_header = re.match(r'^---\\n(.*?)\\n---', markdown_content, re.DOTALL)\n",
    "        if yaml_header:\n",
    "            yaml_content = yaml_header.group(1)\n",
    "            # Parse the YAML content\n",
    "            return yaml.safe_load(yaml_content)\n",
    "        return None\n",
    "    \n",
    "    # LATEX RELATED STUFF\n",
    "    \n",
    "    def _convert_to_latex(self) -> str:\n",
    "        \"\"\"Converts the modified markdown to latex, stores it, and returns it\"\"\"\n",
    "        if SingleDocument.verbose:\n",
    "            print(\"Converting modified markdown of file \"+self.filename+\" to Latex...\")\n",
    "\n",
    "        assert self._markdown_mod  is not None, \"need to have a modified markdown text first!\"\n",
    "\n",
    "        converted = pypandoc.convert_text(source=self._markdown_mod, to='latex',format='md'\n",
    "                                          ,filters=['pandocs_filters/curdir-reference-path-resources.lua'\n",
    "                                                    ,'pandocs_filters/set_graphics_width.lua'\n",
    "                                                    ,'pandocs_filters/mod-reference-path-resources.lua']\n",
    "                                        ,extra_args=[]) #wirte '--standalone' to see full latex output\n",
    "\n",
    "        self._latex_raw = converted\n",
    "\n",
    "        return converted\n",
    "    \n",
    "    def _modify_latex(self) -> str:\n",
    "        \"\"\"Modifies the raw latex string, stores it, and returns it\"\"\"\n",
    "        if SingleDocument.verbose:\n",
    "            print(\"Modifying raw latex of file \"+self.filename+\"...\")\n",
    "\n",
    "        assert self._latex_raw is not None, \"need to convert to latex first!\"\n",
    "\n",
    "        ### CONVERTIONS\n",
    "\n",
    "        # use metadata if available\n",
    "        header = ''\n",
    "\n",
    "        if self._metadata:\n",
    "            metadata: dict = self._metadata\n",
    "            if \"title\" in metadata:\n",
    "                header += \"\\\\mezdoctitle{\"+metadata[\"title\"]+\"}\\n\\n\"\n",
    "\n",
    "        converted = header + self._latex_raw\n",
    "\n",
    "        # scale images to \\columnwidth in case there is no width yet\n",
    "        converted = self._add_width_to_includegraphics(converted)\n",
    "\n",
    "        # make floats floating due to issues in multicolumn\n",
    "        # (https://tex.stackexchange.com/questions/12262/multicol-and-figures)\n",
    "        converted = self._add_option_H_to_figures(converted)\n",
    "\n",
    "        # convert all internal refererences to the latex command\n",
    "        converted = self._replace_zettler_internal_link_with_command(converted)\n",
    "\n",
    "        ### STORING\n",
    "        self._latex_mod = converted\n",
    "        return converted\n",
    "    \n",
    "    def _add_width_to_includegraphics(self, content: str) -> str:\n",
    "        \"\"\"looks for all includegraphics and adds `\\columnwidth` to the graphics in case there \n",
    "        is no defined with or height yet\"\"\"\n",
    "\n",
    "        CM_IN_INCH = 2.54 #conversion from CM to INCH\n",
    "        DPI_PICTURES = 400 #\"true\" DPI the pictures have\n",
    "        DPI_INTERNAL = 96 #amount of DPI that pandocs uses to convert px --> inch\n",
    "        MAX_SIZE_IMAGE_CM = 8.0 #maximal width of an image in CM\n",
    "\n",
    "\n",
    "        # Regex pattern to find \\includegraphics commands\n",
    "        pattern = re.compile(r'(\\\\includegraphics)(\\[[^\\]]*\\])?(\\{[^}]*\\})')\n",
    "\n",
    "        def extract_numbers_from_match(match):\n",
    "            #extract the inches values from a match that looks like '[width=2.66667in,height=2.66667in]'\n",
    "            pattern = r'(\\d+\\.?\\d*)'\n",
    "            # Use re.findall() to extract all matching numbers\n",
    "            numbers = re.findall(pattern, match)\n",
    "            # Convert the extracted strings to floats\n",
    "            numbers = [float(num) for num in numbers]\n",
    "            return numbers\n",
    "\n",
    "        def replace_match(match):\n",
    "            prefix, options, filename = match.groups()\n",
    "            if options is None:\n",
    "                # No options provided, add width=\\columnwidth\n",
    "                return f'{prefix}[width=0.8\\\\columnwidth]{filename}'\n",
    "            elif 'width=' not in options and 'height=' not in options:\n",
    "                # Options provided but without width or height, add width=\\columnwidth\n",
    "                return f'{prefix}[width=0.8\\\\columnwidth{options[1:]}{filename}'\n",
    "            else:\n",
    "                # Options already contain width or height: scale it down and if too\n",
    "                # large do scale\n",
    "                width, height = extract_numbers_from_match(options)\n",
    "                # convert to cm and scale down according to DPI\n",
    "                width *= CM_IN_INCH * DPI_INTERNAL / DPI_PICTURES\n",
    "                height *= CM_IN_INCH * DPI_INTERNAL / DPI_PICTURES\n",
    "\n",
    "                # check if width is too wide --> then return the columnwidth\n",
    "                if(width > MAX_SIZE_IMAGE_CM):\n",
    "                    return f'{prefix}[width=0.8\\\\columnwidth]{filename}'\n",
    "                \n",
    "                return f'{prefix}[width={width}cm,height={height}cm]{filename}'\n",
    "\n",
    "        # Replace all matches in the content\n",
    "        new_content = pattern.sub(replace_match, content)\n",
    "        \n",
    "        return new_content\n",
    "     \n",
    "    def _add_option_H_to_figures(self, latex_text: str) -> str:\n",
    "        # Regular expression to find figure environments without any options\\n\",\n",
    "        pattern = r'(\\\\begin{figure})(?!\\[\\w*\\])'\n",
    "        # Replace those occurrences with the same string but with [H] appended\n",
    "        replacement = r'\\1[H]'\n",
    "\n",
    "        modified_text = re.sub(pattern, replacement, latex_text)\n",
    "        \n",
    "        return modified_text\n",
    "   \n",
    "    def _replace_zettler_internal_link_with_command(self, latex_text: str) -> str:\n",
    "        # replaces `[[20240719012226]]` with the latex command for it\n",
    "\n",
    "        pattern = re.compile(r'\\{\\[\\}\\{\\[\\}\\d{14}\\{\\]\\}\\{\\]\\}') #note: the [[ ]] are compiled into {[}... for soem reason\n",
    "        # Replace the pattern with \\somecommand\n",
    "        result = pattern.sub(r'\\\\mezintreference', latex_text)\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "def merge_documents(documents: list[SingleDocument]) -> str:\n",
    "    \"\"\"Merges a bunch of documents into a single latex stirng\"\"\"\n",
    "\n",
    "    concat = ''\n",
    "\n",
    "    for document in documents:\n",
    "        latex = document.get_latex_text()\n",
    "\n",
    "        # wrap it into a minipage\n",
    "        # latex = \"\\\\begin{minipage}{\\columnwidth}\\n\"\\\n",
    "        #     + latex +\"\\n\"\\\n",
    "        #     + \"\\end{minipage}\\n\"\n",
    "        \n",
    "        # concatenate it\n",
    "        concat += latex\n",
    "\n",
    "    # put it into the tempalte\n",
    "    with open('template/template_outputfile.tex','r') as templatefile:\n",
    "        template_latex = templatefile.read()\n",
    "\n",
    "    merged = template_latex.replace('%%<content_placeholder>%%',concat)\n",
    "\n",
    "    return merged\n",
    "\n",
    "def set_metadata_merged(text: str, author:str, title: str) -> str:\n",
    "    \"\"\"set the author and the title metadat in the results\"\"\"\n",
    "\n",
    "    text = text.replace('%%<TITLE>%%',title)\n",
    "    text = text.replace('%%<AUTHOR>%%',author)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed01fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings\n",
    "\n",
    "author = \"Ford Prefect\"\n",
    "\n",
    "filenames = ['sample1.md','sample2.md','sample3.md', 'sample4.md']\n",
    "filenames = ['sample2.md']\n",
    "filepath_source = 'sample/'\n",
    "filepath_output = 'out/'\n",
    "title = \"Test Samples\"\n",
    "\n",
    "# filenames = ['general_control_diagram.md' #Basics\n",
    "#              ,'optimization-based-control.md'\n",
    "#              ,'linear_time-invariant_system.md'\n",
    "#              ,'bellmans-principle-optimality.md' \n",
    "#              ,'markovian_representation.md'\n",
    "#              ,'SISO_system.md'\n",
    "#              ,'MIMO_system.md'\n",
    "#              ,'dpa_dynamic-programming-approch.md'\n",
    "#              ,'optimal-linear-quadratic-regulation.md' #LQR\n",
    "#              ,'lqr_finite-horizon.md'\n",
    "#              ,'lqr_infinite-horizon.md'\n",
    "#              ,'affine-lqr.md'\n",
    "#              ,'model-predictive-control.md' # MPC\n",
    "#              ,'mpc_stability.md'\n",
    "#              ,'lyapunov_analysis.md'\n",
    "#              ,'mpc_incremental-mpc.md'\n",
    "#              ,'mpc_explicit.md'\n",
    "#              ,'mpc_steady-state-selection.md'\n",
    "#              ,'disturbances.md'\n",
    "#              ,'mpc_disturbance-rejection.md'\n",
    "#              ,'robust_mpc.md'\n",
    "#              ,'robust-mpc_feedback-mpc.md'\n",
    "#              ,'mpc_robust-mpc_soft-constrained-lqr.md'\n",
    "#              ,'economic-mpc.md'\n",
    "#              ,'behavioral-system-theory.md' #Identification\n",
    "#              ,'system-identification.md'\n",
    "#              ,'markov-parameters.md'\n",
    "#              ,'controllability.md'\n",
    "#              ,'controllability-matrix.md'\n",
    "#              ,'observability.md'\n",
    "#              ,'observability-matrix.md'\n",
    "#              ,'impulse_response.md'\n",
    "#              ,'kalman-ho_algorithm.md'\n",
    "#              ,'data-enabled-predictive-control.md' #DeepC\n",
    "#              ,'behavioral_K-step-predictor.md'\n",
    "#              ,'hankel-matrix.md'\n",
    "#              ,'deepc_regularized.md'\n",
    "#              ,'markov-decision-process.md' #MDP\n",
    "#              ,'markov-chain.md'\n",
    "#              ,'policy_for-mdp.md'\n",
    "#              ,'mdp_control-problem.md'\n",
    "#              ,'mdp_q-function.md'\n",
    "#              ,'mdp_value-function.md'\n",
    "#              ,'mdp_finite-horizon.md'\n",
    "#              ,'mdp_infinite-horizon.md'\n",
    "#              ,'monte-carlo-learning.md' #Monte Carlo\n",
    "#              ,'reinforcement-learning.md' #RL\n",
    "#              ,'sarsa_temporal-difference.md'\n",
    "#              ,'q-learning.md'\n",
    "#              ,'policy-gradient.md'\n",
    "#              ]\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/CS2__computational-control/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"Computational Control\"\n",
    "\n",
    "# filenames = ['antrieb_eisenbahn.md'\n",
    "#              ,'antrieb-elektrisch.md'\n",
    "#              ,'haupttransformator.md'\n",
    "#              ,'drosselspule_dc.md'\n",
    "#              ,'fahrmotoren.md'\n",
    "#              ,'elektromotor.md'             \n",
    "#              ,'asynchron-motor.md'\n",
    "#              ,'stromrichter.md'\n",
    "#              ,'netzstromrichter.md'\n",
    "#              ,'zwischenkreis.md'\n",
    "#              ,'motorstromrichter.md'\n",
    "#              ,'hochspannung_eisenbahn.md'\n",
    "#              ,'thermische_auslegung.md'\n",
    "#              ,'diesel-antrieb.md'\n",
    "#              ,'diesel-machanisch.md'\n",
    "#              ,'diesel-hydrostatisch.md'\n",
    "#              ,'diesel-hydrodynamisch.md'\n",
    "#              ,'diesel-elektrisch_gleichstrom.md'\n",
    "#              ,'diesel-elektrisch_umrichter.md'\n",
    "#              ,'gasturbinen-antrieb.md'\n",
    "#              ,'sicherheitssteuerung.md'\n",
    "#              ,'zugbeeinflussung.md'\n",
    "#              ,'etcs.md'\n",
    "#              ,'2024-03-22_sbb-etcs.md'\n",
    "#              ,'energieverbrauch.md'\n",
    "#              ,'energiespeicher.md'\n",
    "#              ,'2024-04-12_traktionsbaterien-gastvortrag.md'\n",
    "#              ,'bahnstromversorgung.md'\n",
    "#              ,'gleichstromsysteme.md'\n",
    "#              ,'wechselstromsystem_sonderfrequenz.md'\n",
    "#              ,'wechselstromsysteme_industriefrequenz.md'\n",
    "#              ,'elektrische-systemkompatibilitaet.md'\n",
    "#              ,'gleisstromkreis.md'\n",
    "#              ,'achsenzaehler.md'\n",
    "#              ,'netzimpendanz.md']\n",
    "# filepath_source = '../../polybox/ZETTLR_STUDIES/EST2__eisenbahn-systemtechnik-2/'\n",
    "# filepath_output = 'out/'\n",
    "# title = \"Eisenbahn-Systemtechnik 2\"\n",
    "\n",
    "# filenames = ['BDE_l01.md'\n",
    "#              ,'BDE_l02.md'\n",
    "#              ,'BDE_l03.md'\n",
    "#              ,'BDE_l04.md'\n",
    "#              ,'BDE_l05.md'\n",
    "#              ,'BDE_l06.md'\n",
    "#              ,'BDE_l07.md'\n",
    "#              ,'BDE_l08.md'\n",
    "#              ,'BDE_l09.md'\n",
    "#              ,'BDE_l10.md'\n",
    "#              ,'BDE_l11.md'\n",
    "#              ,'BDE_l12.md'\n",
    "#              ,'BDE_l13.md'\n",
    "#              ,'BDE_l14.md']\n",
    "filenames = ['big-data_stack.md' #STACK\n",
    "             ,'big_data.md' #GENERAL\n",
    "             ,'relational-database.md'\n",
    "             ,'sql.md'\n",
    "             ,'data-types.md'\n",
    "             ,'cloud-storage.md' #Storage\n",
    "             ,'object-stores.md'\n",
    "             ,'amazon_s3.md'\n",
    "             ,'azure-blob-storage.md'\n",
    "             ,'key-value-storage.md'\n",
    "             ,'distributed-file-system.md' #DFS\n",
    "             ,'hdfs.md'\n",
    "             ,'googlefs.md'\n",
    "             ,'csv.md' #SYNTAX\n",
    "             ,'syntax_tree.md'\n",
    "             ,'json.md'\n",
    "             ,'xml.md'\n",
    "             ,'data-formats.md'\n",
    "             ,'data-model.md' #Data Models\n",
    "             ,'json-data-model.md'\n",
    "             ,'xml-information-set.md'\n",
    "             ,'validation.md' #Validation\n",
    "             ,'jsound.md'\n",
    "             ,'json_schema.md'\n",
    "             ,'xml-schema.md'\n",
    "             ,'dataframe.md'\n",
    "             ,'map-reduce.md' #Processing\n",
    "             ,'yarn.md'\n",
    "             ,'apache-spark.md'\n",
    "             ,'wide-column-store.md' #DATA STORE, Wide Column Store\n",
    "             ,'hbase.md'\n",
    "             ,'spanner.md'\n",
    "             ,'document-stores.md' #Document Store\n",
    "             ,'mongo-db.md'\n",
    "             ,'querying-trees.md' #Querying\n",
    "             ,'jsoniq.md'\n",
    "             ]\n",
    "filepath_source = '../../polybox/ZETTLR_STUDIES/BDE__big-data-for-engineers/'\n",
    "filepath_output = 'out/'\n",
    "title = \"Big Data for Engineers\"\n",
    "\n",
    "SingleDocument.verbose = True\n",
    "\n",
    "### Run\n",
    "\n",
    "documents = []\n",
    "SingleDocument.filepath_source = filepath_source\n",
    "SingleDocument.filepath_output = filepath_output\n",
    "for filename in filenames:\n",
    "    documents.append(SingleDocument(filename))\n",
    "    \n",
    "# for document in documents:\n",
    "#     print(document.get_markdown_text())\n",
    "#     print(document.get_latex_text())\n",
    "\n",
    "latex_total = merge_documents(documents=documents)\n",
    "latex_total = set_metadata_merged(latex_total,author=author,title=title)\n",
    "\n",
    "# print(latex_total)\n",
    "\n",
    "compile_latex(latex_total\n",
    "              ,output_directory=filepath_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
